{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/black0017/3D-GAN-pytorch/blob/master/notebooks/3D_GAN_pytorch.ipynb","timestamp":1670097051780}]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["Examples: \n","https://github.com/xchhuang/simple-pytorch-3dgan\n","https://github.com/black0017/3D-GAN-pytorch\n","https://pytorch3d.org/docs/why_pytorch3d"],"metadata":{"id":"LghsZ4QoqZdP"}},{"cell_type":"code","source":["%matplotlib inline\n","# %matplotlib notebook\n"],"metadata":{"id":"pdme1p7SS4GX","executionInfo":{"status":"ok","timestamp":1671292605556,"user_tz":300,"elapsed":157,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"RmxEe0AEtRiO","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8d280a5-7985-44ee-a151-02f2626bbd39","executionInfo":{"status":"ok","timestamp":1671292629032,"user_tz":300,"elapsed":23147,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"source":["!pip install torch\n","!pip install torchsummary\n","!pip install path.py;\n","!pip install fvcore iopath params"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting path.py\n","  Downloading path.py-12.5.0-py3-none-any.whl (2.3 kB)\n","Collecting path\n","  Downloading path-16.6.0-py3-none-any.whl (26 kB)\n","Installing collected packages: path, path.py\n","Successfully installed path-16.6.0 path.py-12.5.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fvcore\n","  Downloading fvcore-0.1.5.post20221213.tar.gz (50 kB)\n","\u001b[K     |████████████████████████████████| 50 kB 3.0 MB/s \n","\u001b[?25hCollecting iopath\n","  Downloading iopath-0.1.10.tar.gz (42 kB)\n","\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n","\u001b[?25hCollecting params\n","  Downloading params-0.9.0-py3-none-any.whl (11 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore) (1.21.6)\n","Collecting yacs>=0.1.6\n","  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore) (4.64.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore) (2.1.1)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore) (7.1.2)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore) (0.8.10)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath) (4.4.0)\n","Collecting portalocker\n","  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from params) (1.15.0)\n","Building wheels for collected packages: fvcore, iopath\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221213-py3-none-any.whl size=61498 sha256=69702567697941ca1e1e02df849fb87d971d107dc1d348036d1586af3786e5a4\n","  Stored in directory: /root/.cache/pip/wheels/14/6d/5c/4fd3efe9b62aeae1e7e68204b54487df288e58e28f3d13fa1e\n","  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=f57198ee17f3536f5d5a6e39afd80b296b407fac84d415a6421c370ca8204043\n","  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n","Successfully built fvcore iopath\n","Installing collected packages: portalocker, yacs, iopath, params, fvcore\n","Successfully installed fvcore-0.1.5.post20221213 iopath-0.1.10 params-0.9.0 portalocker-2.6.0 yacs-0.1.8\n"]}]},{"cell_type":"code","source":["import os\n","import sys\n","import torch\n","import numpy as np\n","import torch.nn as nn\n","from torchsummary import summary\n","print(torch.__version__)\n","pyt_version_str=torch.__version__.split(\"+\")[0].replace(\".\", \"\")\n","version_str=\"\".join([\n","    f\"py3{sys.version_info.minor}_cu\",\n","    torch.version.cuda.replace(\".\",\"\"),\n","    f\"_pyt{pyt_version_str}\"\n","])\n","version_str"],"metadata":{"id":"fAD2Lk17mIK5","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1671292632653,"user_tz":300,"elapsed":3633,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}},"outputId":"2992d2ec-1a68-429f-ff39-bbef8789906f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["1.13.0+cu116\n"]},{"output_type":"execute_result","data":{"text/plain":["'py38_cu116_pyt1130'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["from path import Path\n","!wget http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n","# !wget http://modelnet.cs.princeton.edu/ModelNet40.zip\n","!unzip -q ModelNet10.zip\n","\n","path = Path(\"ModelNet10\")\n","\n","dir_path = \"ModelNet10\"\n","\n","# loop through the sub directories\n","for root, dirs, files in os.walk(path):\n","        for name in files:\n","            if name == \".DS_Store\":\n","                os.remove(os.path.join(root, name))\n","        for name in dirs:\n","            if name == \".DS_Store\":\n","                os.remove(os.path.join(root, name))\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","params = {\n","    \"epochs\": 500,\n","    \"batch_size\": 32,\n","    \"soft_label\": False,\n","    \"adv_weight\": 0,\n","    \"d_thresh\": 0.8,\n","    \"z_dim\": 200,\n","    \"z_dis\": \"norm\",\n","    \"model_save_step\": 1,\n","    \"g_lr\": 0.0025,\n","    \"d_lr\": 0.00001,\n","    \"beta\": (0.5, 0.999),\n","    \"cube_len\": 32,\n","    \"leak_value\": 0.2,\n","    \"bias\": False,\n","    \"device\": device\n","}"],"metadata":{"id":"3SM7kG8Dldkk","executionInfo":{"status":"ok","timestamp":1671292725764,"user_tz":300,"elapsed":37426,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9c354716-4833-4818-afb4-45888a262712"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-12-17 15:58:08--  http://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n","Resolving 3dvision.princeton.edu (3dvision.princeton.edu)... 128.112.136.74\n","Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.74|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip [following]\n","--2022-12-17 15:58:08--  https://3dvision.princeton.edu/projects/2014/3DShapeNets/ModelNet10.zip\n","Connecting to 3dvision.princeton.edu (3dvision.princeton.edu)|128.112.136.74|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 473402300 (451M) [application/zip]\n","Saving to: ‘ModelNet10.zip’\n","\n","ModelNet10.zip      100%[===================>] 451.47M  67.9MB/s    in 8.7s    \n","\n","2022-12-17 15:58:16 (52.1 MB/s) - ‘ModelNet10.zip’ saved [473402300/473402300]\n","\n"]}]},{"cell_type":"code","source":["# from pytorch3d.io import IO\n","\n","def read_off(file):\n","    if 'OFF' != file.readline().strip():\n","        raise('Not a valid OFF header')\n","    n_verts, n_faces, __ = tuple([int(s) for s in file.readline().strip().split(' ')])\n","    verts = [[float(s) for s in file.readline().strip().split(' ')] for i_vert in range(n_verts)]\n","    faces = [[int(s) for s in file.readline().strip().split(' ')][1:] for i_face in range(n_faces)]\n","    return verts, faces\n","\n","with open(path/\"/content/ModelNet10/bathtub/test/bathtub_0107.off\", 'r') as f:\n","    verts, faces = read_off(f)\n","    \n","i,j,k = np.array(faces).T\n","x,y,z = np.array(verts).T\n","len(x)"],"metadata":{"id":"O6qNVCp_nv_K","executionInfo":{"status":"error","timestamp":1671292632655,"user_tz":300,"elapsed":36,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}},"colab":{"base_uri":"https://localhost:8080/","height":242},"outputId":"fffcacd2-fbdc-4a0d-9ec3-ae5c5be6803e"},"execution_count":5,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-6f8fd38ee597>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m\"/content/ModelNet10/bathtub/test/bathtub_0107.off\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mverts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfaces\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_off\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: Path('/content/ModelNet10/bathtub/test/bathtub_0107.off')"]}]},{"cell_type":"markdown","source":["## Data Loader"],"metadata":{"id":"SQ-OJGwZr_0z"}},{"cell_type":"code","source":["import scipy.ndimage as nd\n","# import scipy.io as io\n","import matplotlib\n","import params\n","\n","# if params.device.type != 'cpu':\n","#     matplotlib.use('Agg')\n","\n","import matplotlib.pyplot as plt\n","import skimage.measure as sk\n","from mpl_toolkits import mplot3d\n","import matplotlib.gridspec as gridspec\n","from torch.utils import data\n","from torch.autograd import Variable\n","import torch\n","import os\n","import time\n","import pickle\n","from torch import optim\n","import torch.nn as nn\n","from torch.autograd import Variable\n","import torch.nn.functional as F\n","import pdb\n","import numpy as np\n","from tqdm.notebook import tqdm\n","from mpl_toolkits.mplot3d import Axes3D\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","mpl.rcParams['savefig.dpi'] = 80\n","mpl.rcParams['figure.dpi'] = 80\n","\n","# Set the device\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda:0\")\n","else:\n","    device = torch.device(\"cpu\")\n","    print(\"WARNING: CPU only, this will be slow!\")\n","\n","def plot_pointcloud(points, title=\"\"):\n","    # Sample points uniformly from the surface of the mesh.\n","    x, y, z = points.clone().detach().cpu().squeeze().unbind(1) \n","    fig = plt.figure(figsize=(5, 5))\n","    ax = Axes3D(fig)\n","    ax.scatter3D(x, z, -y)\n","    ax.set_xlabel('x')\n","    ax.set_ylabel('z')\n","    ax.set_zlabel('y')\n","    ax.set_title(title)\n","    ax.view_init(190, 30)\n","    plt.show()"],"metadata":{"id":"9_WdkdoYsD_9","executionInfo":{"status":"aborted","timestamp":1671292632655,"user_tz":300,"elapsed":27,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","class PointSampler(object):\n","    def __init__(self, output_size):\n","        assert isinstance(output_size, int)\n","        self.output_size = output_size\n","    \n","    def triangle_area(self, pt1, pt2, pt3):\n","        side_a = np.linalg.norm(pt1 - pt2)\n","        side_b = np.linalg.norm(pt2 - pt3)\n","        side_c = np.linalg.norm(pt3 - pt1)\n","        s = 0.5 * ( side_a + side_b + side_c)\n","        return max(s * (s - side_a) * (s - side_b) * (s - side_c), 0)**0.5\n","\n","    def sample_point(self, pt1, pt2, pt3):\n","        # barycentric coordinates on a triangle\n","        # https://mathworld.wolfram.com/BarycentricCoordinates.html\n","        s, t = sorted([random.random(), random.random()])\n","        f = lambda i: s * pt1[i] + (t-s)*pt2[i] + (1-t)*pt3[i]\n","        return (f(0), f(1), f(2))\n","        \n","    \n","    def __call__(self, mesh):\n","        verts, faces = mesh\n","        verts = np.array(verts)\n","        areas = np.zeros((len(faces)))\n","\n","        for i in range(len(areas)):\n","            areas[i] = (self.triangle_area(verts[faces[i][0]],\n","                                           verts[faces[i][1]],\n","                                           verts[faces[i][2]]))\n","            \n","        sampled_faces = (random.choices(faces, \n","                                      weights=areas,\n","                                      cum_weights=None,\n","                                      k=self.output_size))\n","        \n","        sampled_points = np.zeros((self.output_size, 3))\n","\n","        for i in range(len(sampled_faces)):\n","            sampled_points[i] = (self.sample_point(verts[sampled_faces[i][0]],\n","                                                   verts[sampled_faces[i][1]],\n","                                                   verts[sampled_faces[i][2]]))\n","        \n","        return sampled_points\n","\n","\n","class ToTensor(object):\n","    def __call__(self, pointcloud):\n","        assert len(pointcloud.shape)==2\n","\n","        return torch.from_numpy(pointcloud)"],"metadata":{"id":"KqxNsfP4ED-Q","executionInfo":{"status":"aborted","timestamp":1671292632656,"user_tz":300,"elapsed":27,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ModelNet DataLoader\n","from torchvision import transforms, utils\n","num_points = 1024\n","\n","train_transforms = transforms.Compose([\n","                    PointSampler(1024),\n","                    # Normalize(),\n","                    # RandRotation_z(),\n","                    # RandomNoise(),\n","                    ToTensor()\n","                    ])\n","\n","class ModelNetDataset(data.Dataset):\n","\n","    def __init__(self, root, transforms, args, train_or_val=\"train\"):\n","        \n","        \n","        self.root = root\n","        self.listdir = os.listdir(self.root)\n","        self.transforms = transforms\n","        # print (self.listdir)  \n","        # print (len(self.listdir)) # 10668\n","\n","        data_size = len(self.listdir)\n","#        self.listdir = self.listdir[0:int(data_size*0.7)]\n","        self.listdir = self.listdir[0:int(data_size)]\n","        \n","        print ('data_size =', len(self.listdir)) # train: 10668-1000=9668\n","        self.args = args\n","\n","    def __preproc__(self, file):\n","        verts, faces = read_off(file)\n","        if self.transforms:\n","            pointcloud = self.transforms((verts, faces))\n","        return pointcloud\n","\n","    def __getitem__(self, index):\n","        with open(self.root + \"/\" + self.listdir[index], 'r') as f:\n","            pointcloud = self.__preproc__(f)\n","        # mesh = IO().load_mesh(self.root + \"/\" + self.listdir[index], device=device)\n","        # # return torch.FloatTensor(mesh)\n","        # points = sample_points_from_meshes(mesh, num_points)\n","        # # print(points.data[0:5], points.shape)\n","        # points = points.reshape((num_points,3))\n","        # # print(points.data[0:5], points.shape)\n","        return pointcloud\n","\n","    def __len__(self):\n","        return len(self.listdir)\n","\n","def generateZ(args, batch):\n","\n","    if params[\"z_dis\"] == \"norm\":\n","        Z = torch.Tensor(batch, params[\"z_dim\"]).normal_(0, 0.33).to(params[\"device\"])\n","    elif params[\"z_dis\"] == \"uni\":\n","        Z = torch.randn(batch, params[\"z_dim\"]).to(params[\"device\"]).to(params[\"device\"])\n","    else:\n","        print(\"z_dist is not normal or uniform\")\n","\n","    return Z\n","\n","# custom weights initialization called on netG and netD\n","def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"],"metadata":{"id":"1fToJfv-siKJ","executionInfo":{"status":"aborted","timestamp":1671292632657,"user_tz":300,"elapsed":28,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dsets_path = \"/content/ModelNet10/bed/train\"\n","args = None\n","\n","train_dsets = ModelNetDataset(dsets_path, train_transforms, args, \"train\")\n","print(len(train_dsets))\n","mesh = train_dsets[0]\n","print(mesh.shape)\n","# mesh2.num_faces_per_mesh()\n","plot_pointcloud(mesh, \"Test\")"],"metadata":{"id":"OXkhrF9tt0qn","executionInfo":{"status":"aborted","timestamp":1671292632657,"user_tz":300,"elapsed":28,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#PARAMS\n","\n","# Batch size during training\n","batch_size = 5\n","\n","# Number of channels in the training images. For color images this is 3\n","nc = 3\n","\n","# Size of z latent vector (i.e. size of generator input)\n","nz = 1024\n","\n","# Size of feature maps in generator\n","ngf = 1024\n","\n","# Size of feature maps in discriminator\n","ndf = 1024\n","\n","# Number of training epochs\n","num_epochs = 5\n","\n","# Learning rate for optimizers\n","# lr = 0.0002\n","lr = 0.0002\n","\n","# Beta1 hyperparam for Adam optimizers\n","beta1 = 0.5\n","\n","# Number of GPUs available. Use 0 for CPU mode.\n","ngpu = 1\n","\n","e_hidden = 1024        # Number of hidden units in the encoder. Chosen based on AEVB paper page 7, section \"Marginal Likelihood\"\n","d_hidden = 1024        # Number of hidden units in the decoder. Chosen based on AEVB paper page 7, section \"Marginal Likelihood\"\n","latent_dim = 3  \n","\n","train_dset_loaders = torch.utils.data.DataLoader(train_dsets, batch_size=batch_size, shuffle=True, num_workers=1)"],"metadata":{"id":"xumasu61UmrK","executionInfo":{"status":"aborted","timestamp":1671292632658,"user_tz":300,"elapsed":29,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdWpJZhRxNVC"},"source":["## Discriminator (PointNet)"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","import torch.nn.functional as F\n","\n","class Tnet(nn.Module):\n","    def __init__(self, k=3):\n","        super().__init__()\n","        self.k=k\n","        self.conv1 = nn.Conv1d(k,64,1)\n","        self.conv2 = nn.Conv1d(64,128,1)\n","        self.conv3 = nn.Conv1d(128,1024,1)\n","        self.fc1 = nn.Linear(1024,512)\n","        self.fc2 = nn.Linear(512,256)\n","        self.fc3 = nn.Linear(256,k*k)\n","\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(1024)\n","        self.bn4 = nn.BatchNorm1d(512)\n","        self.bn5 = nn.BatchNorm1d(256)\n","\n","\n","    def forward(self, input):\n","        # input.shape == (bs,n,3)\n","        bs = input.size(0)\n","        xb = F.relu(self.bn1(self.conv1(input)))\n","        xb = F.relu(self.bn2(self.conv2(xb)))\n","        xb = F.relu(self.bn3(self.conv3(xb)))\n","        pool = nn.MaxPool1d(xb.size(-1))(xb)\n","        flat = nn.Flatten(1)(pool)\n","        xb = F.relu(self.bn4(self.fc1(flat)))\n","        xb = F.relu(self.bn5(self.fc2(xb)))\n","\n","        #initialize as identity\n","        init = torch.eye(self.k, requires_grad=True).repeat(bs,1,1)\n","        if xb.is_cuda:\n","            init=init.cuda()\n","        matrix = self.fc3(xb).view(-1,self.k,self.k) + init\n","        return matrix\n","\n","\n","class Transform(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.input_transform = Tnet(k=3)\n","        self.feature_transform = Tnet(k=64)\n","        self.conv1 = nn.Conv1d(3,64,1)\n","\n","        self.conv2 = nn.Conv1d(64,128,1)\n","        self.conv3 = nn.Conv1d(128,1024,1)\n","\n","\n","        self.bn1 = nn.BatchNorm1d(64)\n","        self.bn2 = nn.BatchNorm1d(128)\n","        self.bn3 = nn.BatchNorm1d(1024)\n","\n","    def forward(self, input):\n","        matrix3x3 = self.input_transform(input)\n","        # batch matrix multiplication\n","        xb = torch.bmm(torch.transpose(input,1,2), matrix3x3).transpose(1,2)\n","\n","        xb = F.relu(self.bn1(self.conv1(xb)))\n","\n","        matrix64x64 = self.feature_transform(xb)\n","        xb = torch.bmm(torch.transpose(xb,1,2), matrix64x64).transpose(1,2)\n","\n","        xb = F.relu(self.bn2(self.conv2(xb)))\n","        xb = self.bn3(self.conv3(xb))\n","        xb = nn.MaxPool1d(xb.size(-1))(xb)\n","        output = nn.Flatten(1)(xb)\n","        return output, matrix3x3, matrix64x64\n","\n","class PointNet(nn.Module):\n","    def __init__(self, classes = 2):\n","        super().__init__()\n","        self.transform = Transform()\n","        self.fc1 = nn.Linear(1024, 512)\n","        self.fc2 = nn.Linear(512, 256)\n","        self.fc3 = nn.Linear(256, classes)        \n","\n","        self.bn1 = nn.BatchNorm1d(512)\n","        self.bn2 = nn.BatchNorm1d(256)\n","        self.dropout = nn.Dropout(p=0.3)\n","        self.logsoftmax = nn.LogSoftmax(dim=-1)\n","        self.softmax = nn.Softmax(dim=-1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, input):\n","        input = input.float()\n","        xb, matrix3x3, matrix64x64 = self.transform(input)\n","        xb = F.relu(self.bn1(self.fc1(xb)))\n","        xb = F.relu(self.bn2(self.dropout(self.fc2(xb))))\n","        # print(\"xb\",xb.shape)\n","        output = self.fc3(xb)\n","        # print(\"output of discrim\", output.shape, output, output.reshape(-1).shape, output.reshape(-1))\n","        output.float\n","        return self.logsoftmax(output), matrix3x3, matrix64x64 #self.logsoftmax(output), torch.sigmoid(output.reshape(-1))\n","\n","netD = PointNet()\n","netD.to(device)\n","\n","# Handle multi-gpu if desired\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netD = nn.DataParallel(netD, list(range(ngpu)))\n","\n","# Apply the weights_init function to randomly initialize all weights\n","#  to mean=0, stdev=0.2.\n","netD.apply(weights_init)\n","\n","# Print the model\n","print(netD)"],"metadata":{"id":"LMg8QgYc1cUe","executionInfo":{"status":"aborted","timestamp":1671292632659,"user_tz":300,"elapsed":30,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xDCCLjoaxW5B"},"source":["## Generator"]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self):\n","    \"\"\"\n","    Encoder Network. Must inherit from `nn.Module` provided by Pytorch. We only need to define 2 things:\n","    \n","    1) The components of the network (layers, activation functions, etc). This is done in __init__().\n","    2) How the network uses such components to transform the network input into an output. This is done in a method called `forward()`.\n","    \"\"\"\n","    super(Encoder, self).__init__()\n","    # Define Fully-Connected FeedForward Connections\n","    self.hidden = nn.Linear(in_features=3 * num_points, out_features=e_hidden)\n","    # We need two separate layers. One is used for mu one is used for logvar.\n","    self.mu_layer     = nn.Linear(in_features=e_hidden, out_features=latent_dim)\n","    self.logvar_layer = nn.Linear(in_features=e_hidden, out_features=latent_dim)\n","    \n","  def forward(self, x):\n","    \"\"\"Defines how the network transforms the input x into an encoded representation.\"\"\"\n","    # Pass input through the first set of connections\n","    # print(\"encoder x\", x.shape)\n","    # print(x[0:2])\n","    x = F.relu(self.hidden(x))\n","    # print(\"after relu x\", x.shape)\n","    # Now pass it to one set of connections to get mu, and to another set of connections \n","    # to get logvar\n","    return self.mu_layer(x), self.logvar_layer(x)\n","\n","class Decoder(nn.Module):\n","  def __init__(self):\n","    \"\"\"\n","    Decoder Network. Works similarly to the encoder, except it takes an input from the latent space\n","    and then outputs an image.\n","    \"\"\"\n","    super(Decoder, self).__init__()\n","    # Define Fully-Connected FeedForward Connections\n","    self.hidden = nn.Linear(in_features=latent_dim, out_features=d_hidden)\n","    # Second set of FC connections. Here we only want one output\n","    self.output_layer = nn.Linear(in_features=d_hidden, out_features=3 * num_points)\n","\n","  def forward(self, z):\n","    \"\"\"Defines how the network transforms the latent input z into a flatten image.\"\"\"\n","    # Notice that we use a sigmoid function at the end to restrict output values between \n","    # 0 and 1 so they can be interpreted as probabilities (?)\n","    # print(\"decoder x\", z.shape)\n","    z = F.relu(self.hidden(z))\n","    # print(\"decoder z\", z.shape)\n","    return torch.sigmoid(self.output_layer(z))\n","\n","class SimpleVAE(nn.Module):\n","  def __init__(self):\n","    \"\"\"Puts together Encoder & Decoder with the reparametrization trick.\"\"\"\n","    super(SimpleVAE, self).__init__()\n","    self.encoder = Encoder()\n","    self.decoder = Decoder()\n","\n","  def sample_latent(self, mu, logvar):\n","    if self.training:\n","      # Get standard normal in the shape of mu\n","      eps = torch.randn_like(mu)\n","      # Use logarithmic properties to transform logvar to std. Then multiply\n","      # and sum by latent mu\n","      return eps.mul(torch.exp(0.5*logvar)).add_(mu)\n","    else:   # This is used when testing \n","      return mu    \n","\n","  def forward(self, x):\n","    \"\"\"Transforms image into latent and then back to its reconstruction.\"\"\"\n","    # Feed image to encoder. Obtain mean and logvar for the latent space\n","    # print(\"shapes of x\", x.shape, x.view(-1, 3 * 1024).shape)\n","    # print(\"vae forward x reshape\", x.view(-1, 3 * 1024).shape)\n","    # print(x.view(-1, 3 * 1024))\n","    latent_mu, latent_logvar = self.encoder(x.view(-1, 3 * num_points)) # (3 x 1024 * b_size)\n","    # print(\"latent vars\", latent_mu.shape, latent_logvar.shape)\n","    # Sample from the latent space with the give mean and variance using the \n","    # reparametrization trick\n","    z = self.sample_latent(latent_mu, latent_logvar)\n","    # print(\"vae forward z\", z.shape)\n","    # Decode the latent representation\n","    return self.decoder(z), latent_mu, latent_logvar   \n","\n","# for evaluation\n","# testpoints = Dataset.sample_batch()\n","# fake, mu, logvar = netG(testpoints)\n","# some_value = vae_loss(testpoints, fake, mu, logvar)\n","\n","def vae_loss(image, reconstruction, mu, logvar):\n","  \"\"\"Loss for the Variational AutoEncoder.\"\"\"\n","  # Compute the binary_crossentropy.\n","  # Notice that we reshape them because in practice we don't receive just 1 image and 1 reconstruction, but we receive a whole batch!\n","  # print(\"reshape\", image.shape, image.reshape(-1,3* num_points).shape)\n","  reconstruction_loss = F.binary_cross_entropy(input=reconstruction.reshape(-1, 3 * num_points), target=image.reshape(-1, 3 * num_points), reduction='sum')\n","  # Compute KL divergence using formula (closed-form)\n","  kl = 0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n","  return reconstruction_loss - kl\n","\n","# Create the generator\n","netG = SimpleVAE().to(device)\n","\n","# Handle multi-gpu if desired\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netG = nn.DataParallel(netG, list(range(ngpu)))\n","\n","# Apply the weights_init function to randomly initialize all weights\n","#  to mean=0, stdev=0.02.\n","netG.apply(weights_init)\n","\n","# Print the model\n","print(netG)"],"metadata":{"id":"21HkvjgAC-Xn","executionInfo":{"status":"aborted","timestamp":1671292632659,"user_tz":300,"elapsed":30,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\"\"\"\n","A Convolutional Variational Autoencoder\n","\"\"\"\n","class PointEncoder(nn.Module):\n","    def __init__(self, zdim=1024, input_dim=3):\n","      super(PointEncoder, self).__init__()\n","      self.zdim = zdim\n","      self.conv1 = torch.nn.Conv1d(input_dim, 128, 1)  # 64\n","      self.conv2 = torch.nn.Conv1d(128, 128, 1)  # 64\n","      self.conv3 = torch.nn.Conv1d(128, 256, 1)  # 128\n","      self.conv4 = torch.nn.Conv1d(256, 512, 1)  # 512\n","\n","      self.fc1 = torch.nn.Linear(512, 256)  # 128\n","      self.fc2 = torch.nn.Linear(256, 128)  #\n","      self.fc3 = torch.nn.Linear(128, zdim)  #\n","\n","      self.fcm = torch.nn.Linear(512, zdim)\n","      self.fcv = torch.nn.Linear(512, zdim)\n","\n","      self.relu = nn.ReLU()\n","      self.leakyrelu = nn.LeakyReLU(0.2)\n","\n","    def\tforward(self, x):\n","      print(x.shape)\n","      x = x.transpose(1,2) # BxCxN\n","      x = self.leakyrelu(self.conv1(x))\n","      x = self.leakyrelu(self.conv2(x))\n","      x = self.leakyrelu(self.conv3(x))\n","      x = self.leakyrelu(self.conv4(x))\n","\n","      x = torch.max(x, 2, keepdim=True)[0]\n","      x = x.view(-1, 512)\n","\n","      mu = self.fcm(x)\n","      logvar = self.fcv(x)\n","\n","      return mu, logvar\n","\n","class PointDecoder(nn.Module):\n","    def __init__(self, zdim=1024, out_pts=1024):\n","      super(PointDecoder, self).__init__()\n","      self.zdim = zdim\n","      self.out_pts = out_pts\n","      self.fc1 = torch.nn.Linear(zdim, 256)\n","      self.fc2 = torch.nn.Linear(256, 1024)\n","      self.fc3 = torch.nn.Linear(1024, 1024*3)\n","      self.relu = nn.ReLU()\n","      self.leakyrelu = nn.LeakyReLU(0.2)\n","      self.tanh = nn.Tanh()\n","\n","    def forward(self,x):\n","      x = self.leakyrelu(self.fc1(x))\n","      x = self.leakyrelu(self.fc2(x))\n","      x = self.fc3(x)\n","      x = x.view(x.shape[0], -1, 3)\n","      x = self.tanh(x)\n","      return x\n","\n","class VAE(nn.Module):\n","    def __init__(self, channels=3, featureDim=1024 * batch_size * 64, zDim=1024):\n","        super(VAE, self).__init__()\n","\n","        self.encoder = PointEncoder()\n","        self.decoder = PointDecoder()\n","\n","    def reparameterize(self, mu, logVar):\n","\n","        #Reparameterization takes in the input mu and logVar and sample the mu + std * eps\n","        std = torch.exp(logVar/2)\n","        eps = torch.randn_like(std)\n","        return mu + std * eps\n","\n","    def sample_latent(self, mu, logvar):\n","      if self.training:\n","        # Get standard normal in the shape of mu\n","        eps = torch.randn_like(mu)\n","        # Use logarithmic properties to transform logvar to std. Then multiply\n","        # and sum by latent mu\n","        return eps.mul(torch.exp(0.5*logvar)).add_(mu)\n","      else:   # This is used when testing \n","        return mu  \n","\n","    def forward(self, x):\n","\n","        # The entire pipeline of the VAE: encoder -> reparameterization -> decoder\n","        # output, mu, and logVar are returned for loss computation\n","        mu, logVar = self.encoder(x)\n","        z = self.reparameterize(mu, logVar)\n","        out = self.decoder(z)\n","        return out, mu, logVar\n","\n","netG = VAE().to(device)\n","\n","# Handle multi-gpu if desired\n","if (device.type == 'cuda') and (ngpu > 1):\n","    netG = nn.DataParallel(netG, list(range(ngpu)))\n","\n","# Apply the weights_init function to randomly initialize all weights\n","#  to mean=0, stdev=0.02.\n","netG.apply(weights_init)\n","\n","# Print the model\n","print(netG)"],"metadata":{"id":"FzS8kMOusxCi","executionInfo":{"status":"aborted","timestamp":1671292632660,"user_tz":300,"elapsed":30,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initialize BCELoss function\n","criterion = nn.BCELoss()\n","# criterion = nn.NLLLoss()\n","\n","# Create batch of latent vectors that we will use to visualize\n","#  the progression of the generator\n","noise = torch.randn(batch_size, nz, 3, device=device)\n","\n","# Establish convention for real and fake labels during training\n","real_label = 1.\n","fake_label = 0.\n","\n","# Setup Adam optimizers for both G and D\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n","\n","def pointnetloss(outputs, labels, m3x3, m64x64, alpha = 0.0001):\n","    # criterion = torch.nn.NLLLoss()\n","    criterion = nn.BCELoss()\n","    bs=labels.size(0)\n","    id3x3 = torch.eye(3, requires_grad=True).repeat(bs,1,1)\n","    id64x64 = torch.eye(64, requires_grad=True).repeat(bs,1,1)\n","    if outputs.is_cuda:\n","        id3x3=id3x3.cuda()\n","        id64x64=id64x64.cuda()\n","    diff3x3 = id3x3-torch.bmm(m3x3,m3x3.transpose(1,2))\n","    diff64x64 = id64x64-torch.bmm(m64x64,m64x64.transpose(1,2))\n","    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)+torch.norm(diff64x64)) / float(bs)"],"metadata":{"id":"H4_1TNUeV-10","executionInfo":{"status":"aborted","timestamp":1671292632661,"user_tz":300,"elapsed":31,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Train"],"metadata":{"id":"-HmPf8gXphzA"}},{"cell_type":"code","source":["# Training Loop\n","\n","# Lists to keep track of progress\n","G_losses = []\n","D_losses = []\n","iters = 0\n","\n","print(\"Starting Training Loop...\")\n","# For each epoch\n","for epoch in range(num_epochs):\n","    # For each batch in the dataloader\n","    for i, data in enumerate(train_dset_loaders, 0):\n","\n","        ############################\n","        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n","        ###########################\n","        ## Train with all-real batch\n","        # print(data.shape)\n","        netD.zero_grad()\n","        # Format batch\n","        real_cpu = data.to(device) # was data[0]\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n","        # print(label.shape)\n","        # Forward pass real batch through D\n","        # print(\"input shape\", real_cpu.shape)\n","        # print(real_cpu)\n","        # print(\"tranpose input shape\", real_cpu.transpose(1,2).shape)\n","        output, m3, m64 = netD(real_cpu.transpose(1,2)) #.view(-1)\n","        # output = netD(real_cpu.transpose(1,2))\n","        # print(\"output\", output)\n","        # print(\"output shape\", output.shape)\n","        # Calculate loss on all-real batch\n","        # errD_real = pointnetloss(output, label, m3, m64)\n","        # print(\"error_real\", errD_real)\n","        errD_real = criterion(output, label) ##\n","        # Calculate gradients for D in backward pass\n","        errD_real.backward(retain_graph=True)\n","        D_x = output.mean().item()\n","\n","        ## Train with all-fake batch\n","        # Generate batch of latent vectors\n","        # noise = torch.randn(b_size, nz, 3, device=device, dtype=torch.float) #Old line, replace with next uncommented line\n","        # print(\"noise shape:\", noise.shape)\n","        # print(noise)\n","        # Generate fake image batch with G\n","        fake, latent_mu, latent_logvar = netG(real_cpu.float()) #change the arg to what it is now\n","        # fake = netG(noise)\n","        # print(\"fake shpe\", fake.shape)\n","        label.fill_(fake_label)\n","        # print(\"fake plus gen outputs\",  fake.shape, latent_mu.shape, latent_logvar.shape)\n","        # print(\"fake gen\", fake.transpose(1,2).shape)\n","        # print(fake)\n","        # Classify all fake batch with D\n","        # fake = fake.reshape(b_size, num_points, 3)\n","        # print(fake.shape)\n","        output, m3, m64 = netD(fake.transpose(1,2)) #.view(-1)\n","        # output = netD(fake.transpose(1,2))\n","        # print(\"output fake\", output)\n","        # print(\"output and label fake shape\", output.shape, label.shape)\n","        # Calculate D's loss on the all-fake batch\n","        # errD_fake = pointnetloss(output, label, m3, m64)\n","        errD_fake = criterion(output, label)\n","        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n","        errD_fake.backward(retain_graph=True)\n","        D_G_z1 = output.mean().item()\n","        # Compute error of D as sum over the fake and the real batches\n","        errD = errD_real + errD_fake\n","        # Update D\n","        optimizerD.step()\n","\n","        ############################\n","        # (2) Update G network: maximize log(D(G(z)))\n","        ###########################\n","        netG.zero_grad()\n","        label.fill_(real_label)  # fake labels are real for generator cost\n","        # print(\"label, update G\", label)\n","        # Since we just updated D, perform another forward pass of all-fake batch through D\n","        output, m3, m64 = netD(fake.transpose(1,2)) # .view(-1)\n","        # Calculate G's loss based on this output\n","        # print(\"calculate G loss\", output.shape, label.shape)\n","        # errG = vae_loss(real_cpu.transpose(1,2), fake.transpose(1,2), latent_mu, latent_logvar) \n","        # errG = pointnetloss(output, label, m3, m64) \n","        errG = criterion(output, label)\n","        # Calculate gradients for G\n","        errG.backward(retain_graph=True)\n","        D_G_z2 = output.mean().item()\n","        # Update G\n","        optimizerG.step()\n","\n","        # Output training stats\n","        # if i % 50 == 0:\n","        print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","              % (epoch, num_epochs, i, len(train_dset_loaders),\n","                errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","\n","        # Save Losses for plotting later\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        # Check how the generator is doing by saving G's output on fixed_noise\n","        # if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_dset_loaders)-1)):\n","        #     with torch.no_grad():\n","        #         fake, latent_mu, latent_logvar = netG(fixed_noise)\n","        #         fake = fake.detach().cpu()\n","            # img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n","\n","        iters += 1"],"metadata":{"id":"PJad8Tj5prJY","executionInfo":{"status":"aborted","timestamp":1671292632661,"user_tz":300,"elapsed":31,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","def plot_point_cloud(point_cloud):\n","  # Convert the point cloud tensor to a NumPy array\n","  point_cloud = point_cloud.numpy()\n","\n","  # Extract the x, y, and z coordinates from the point cloud\n","  x = point_cloud[:, 0]\n","  y = point_cloud[:, 1]\n","  z = point_cloud[:, 2]\n","\n","  # Create a new figure and set the 3D projection\n","  fig = plt.figure()\n","  ax = fig.add_subplot(111, projection='3d')\n","\n","  # Plot the points in 3D space\n","  ax.scatter(x, y, z)\n","\n","  # Show the plot\n","  plt.show()\n","\n","def plot_losses(losses, num_epochs):\n","  plt.plot(range(1, num_epochs+1), losses)\n","  plt.xlabel('Epoch')\n","  plt.ylabel('Loss')\n","  plt.show()"],"metadata":{"id":"eoFw3J8qO7i4","executionInfo":{"status":"aborted","timestamp":1671292632662,"user_tz":300,"elapsed":32,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(G_losses)\n","plot_losses(G_losses, len(G_losses))\n","plot_losses(D_losses, len(D_losses))"],"metadata":{"id":"iBPWC-9rTroC","executionInfo":{"status":"aborted","timestamp":1671292632663,"user_tz":300,"elapsed":33,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["netG.eval()\n","train_dset_loaders = torch.utils.data.DataLoader(train_dsets, batch_size=batch_size, shuffle=True, num_workers=1)\n","z = next(iter(train_dset_loaders))\n","with torch.no_grad():\n","  # Sample from standard normal distribution\n","  # z = torch.randn(batch_size, nz, 3, device=device)\n","\n","  plot_point_cloud(z[0])\n","\n","  # Reconstruct points from sampled latent vectors\n","  recon_points, latent_mu, lateng_logvar = netG(z.float())\n","  # recon_points = netG(z)\n","  print(recon_points.shape)\n","  recon_points = recon_points.reshape(batch_size, num_points, 3)\n","  print(recon_points.shape)\n","  # recon_points = recon_points.view(recon_points.size(0), 1, 28, 28)\n","  recon_points = recon_points.cpu()\n","  # recon_points = recon_points.clamp(0, 1)\n","  print(recon_points.shape)\n","  plot_point_cloud(recon_points[0])\n","\n","  # Plot Generated points"],"metadata":{"id":"tFJkUb8jN-dj","executionInfo":{"status":"aborted","timestamp":1671292632664,"user_tz":300,"elapsed":34,"user":{"displayName":"Joseph Edell","userId":"13290937878441558264"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i2GyllAQxc-R"},"source":["## Test"]}]}